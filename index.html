<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1168479-8"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-1168479-8');
    </script>
    <style>
      html { scroll-behavior: smooth; }
      body { font-family: 'Lato', Verdana, Helvetica, sans-serif; }
      p {line-height: 25px;}
      main.container {max-width: 1000px;}
      span.p-title {font-size: 19px;}
      span.p-authors {font-style: normal;}
      span.p-conference {font-style: italic;}
      .p-bibtex {font-size: 12px; margin-bottom: 0px; max-width: 650px; text-align: left;}
      img.p-teaser {width: 160px;}
      img.p-project {
        width: 320px;
        border-radius: 12px;
        border: 1px solid #ddd;
      }
      span.project {
        text-align: justify;
      }
      img.profile {
        width: 160px;
        height: 160px;
        border: 1px solid #ddd;
        padding: 5px;
        margin-bottom: 0px;
        box-shadow: 0 -1px 5px 1px rgba(200, 200, 200, 0.5);
      }

      /* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 400;
  src: local('Lato Italic'), local('Lato-Italic'), url(https://fonts.gstatic.com/s/lato/v15/S6u8w4BMUTPHjxsAUi-qNiXg7eU0.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 400;
  src: local('Lato Italic'), local('Lato-Italic'), url(https://fonts.gstatic.com/s/lato/v15/S6u8w4BMUTPHjxsAXC-qNiXg7Q.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 700;
  src: local('Lato Bold Italic'), local('Lato-BoldItalic'), url(https://fonts.gstatic.com/s/lato/v15/S6u_w4BMUTPHjxsI5wq_FQftx9897sxZ.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 700;
  src: local('Lato Bold Italic'), local('Lato-BoldItalic'), url(https://fonts.gstatic.com/s/lato/v15/S6u_w4BMUTPHjxsI5wq_Gwftx9897g.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 400;
  src: local('Lato Regular'), local('Lato-Regular'), url(https://fonts.gstatic.com/s/lato/v15/S6uyw4BMUTPHjxAwXiWtFCfQ7A.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 400;
  src: local('Lato Regular'), local('Lato-Regular'), url(https://fonts.gstatic.com/s/lato/v15/S6uyw4BMUTPHjx4wXiWtFCc.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 700;
  src: local('Lato Bold'), local('Lato-Bold'), url(https://fonts.gstatic.com/s/lato/v15/S6u9w4BMUTPHh6UVSwaPGQ3q5d0N7w.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 700;
  src: local('Lato Bold'), local('Lato-Bold'), url(https://fonts.gstatic.com/s/lato/v15/S6u9w4BMUTPHh6UVSwiPGQ3q5d0.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}

    </style>

    <title>Francis Engelmann</title>
  </head>

  <body>
    <main class="container">
      <div class="mt-5 mb-5 text-center">
          <div class="text-center text-sm-left">
            <p align="justify">

<main class="container">
      <div class="mt-5 mb-5 text-center">
          <img src="profile.jpg" alt="profile" class="rounded-circle profile mr-3 mb-sm-1 float-sm-left" style="margin-top: 25px" />
          <div class="text-center text-sm-left">
            <h2>Francis Engelmann</h2>
            <p align="justify">
            I am a postdoc at <a href="https://www.stanford.edu">Stanford University</a> with <a href="https://profiles.stanford.edu/leonidas-guibas">Prof. Leonidas Guibas</a> and <a href="https://web.stanford.edu/~bohg/">Prof. Jeannette Bohg</a>.
            Previously, I was a postdoctoral research fellow at
            <a target="_blank" href="https://ethz.ch/en.html">ETH Zurich<a> <a href="https://ai.ethz.ch/">AI Center</a> working with <a href="https://people.inf.ethz.ch/marc.pollefeys/">Prof. Dr. Marc Pollefeys</a>,
            and a visiting researcher with <a target="_blank"  href="https://federicotombari.github.io/">Federico Tombari</a> at Google Zurich.
            Before joining ETH Zurich, I finished my Ph.D. in Computer Vision, Machine Learning and 3D Scene Understanding
             in the
            <a target="_blank" href="https://www.vision.rwth-aachen.de/">Computer Vision Group</a>
            of
            <a target="_blank" href="https://scholar.google.com/citations?user=ZcULDB0AAAAJ">Prof. Dr. Bastian Leibe</a>
            at
            <a target="_blank" href="https://www.rwth-aachen.de/go/id/a/?lidx=1">RWTH Aachen University</a>
            and spent some time at <a target="_blank" href="https://x.company/projects/intrinsic/">Google X</a> in Munich with
            <a target="_blank" href="https://research.google/people/106293/">Martin Bokeloh</a>
             and Google Research Zurich with
            <a target="_blank" href="http://www.krematas.com/">Kostas Rematas</a>, as well as Apple in California.
          </p>
          <p align="center">
            <a target="_blank" href="https://scholar.google.com/citations?user=-xOsXi8AAAAJ"><i class="ai ai-google-scholar-square ai-2x"></i></a>
            &nbsp;
            <a target="_blank" href="https://github.com/francisengelmann"><i class="fa fa-github" style="font-size:32px"></i></a>
            &nbsp;
            <a target="_blank" href="https://www.linkedin.com/in/francis-engelmann-8b4b5467/"><i class="fa fa-linkedin-square" style="font-size:32px"></i></a>
            &nbsp;
            <a target="_blank" href="https://twitter.com/FrancisEngelman"><i class="fa fa-twitter" style="font-size:32px"></i></a>
            &nbsp;
            <a target="_blank" href="mailto:francis.engelmann@ai.ethz.ch"><i class="fa fa-envelope" style="font-size:32px"></i></a>
            </p>
          </div>
      </div>

      <!--<div align="center">
        <a href="https://ethz.ch/en.html"><img src="media/eth_logo.png" height="30" style="margin: 5px; padding: 5px"></a>
        <a href="https://research.google/"><img src="media/google_logo.png" height="30" style="margin: 10px"></a>
        <a href="https://x.company"><img src="media/x_logo.svg" height="30" style="margin: 10px"></a>
        <a href="https://www.apple.com/"><img src="media/apple_logo.png" height="30" style="margin: 10px"></a>
        <a href="https://www.rwth-aachen.de/"><img src="media/rwth_logo.png" height="30" style="margin: 10px"></a>
      </div>-->
    <h3 class="mb-3 text-center text-sm-left">News</h3>

    <ul class="list-unstyled">

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Feb 2025</b>
        We have 2 papers accepted at <a target="_blank" href="https://cvpr.thecvf.com/Conferences/2025">CVPR'25</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jan 2025</b>
        <a href="https://search3d-segmentation.github.io/">Search3D</a> our approach for hierarchical open-vocabulary 3D scene segmentation was accepted at <a href="https://www.ieee-ras.org/publications/ra-l" target="_blank">RA-L</a>.
      </li>


      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Dec 2024</b>
        The 4<sup>th</sup> iteration of our <a href="https://opensun3d.github.io/">Open-Vocabulary 3D Scene Understanding Workshop</a> will be held at <a href="https://cvpr.thecvf.com/Conferences/2025" target="_blank">CVPR'25</a> in Nashville, TN.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Oct 2024</b>
        We have 2 papers accepted at <a target="_blank" href="https://wacv2025.thecvf.com/">WACV'25</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Sept 2024</b>
        I moved to Stanford University to work with Leo Guibas and Jeannette Bohg on computer vision for robotics.
      </li>
      
      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Sept 2024</b>
        I will serve as areas chair (AC) for <a target="_blank" href="https://cvpr.thecvf.com/Conferences/2025">CVPR'25</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>July 2024</b>
        We have 4 papers accepted at <a href="https://eccv.ecva.net">ECCV'24</a> in Milan, among them <a href="https://segment3d.github.io">Segment3D</a>!
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>July 2024</b>
        I will serve as areas chair (AC) for <a target="_blank" href="https://3dvconf.github.io/2025/">3DV'25</a> and <a target="_blank" href="https://wacv2025.thecvf.com">WACV'25</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>May 2024</b>
        I was recognized as outstanding reviewer for <a href="https://media.eventhosts.cc/Conferences/CVPR2024/CVPR_main_conf_2024.pdf" target="_blank">CVPR 2024</a> (top 2%).
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Apr 2024</b>
        The third iteration of our <a href="https://opensun3d.github.io/index_eccv24.html">Open-Vocabulary 3D Scene Understanding Workshop</a> will be held at <a href="https://eccv.ecva.net" target="_blank">ECCV'24</a> in Milan.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>May 2024</b>
        Our  <a href="https://spot-compose.github.io" target="_blank">Spot-Compose</a> received a <b>üèÜ Best Paper Award</b> at the <a href="https://mobile-manipulation.net/events/moma2024/">ICRA'24 MOMA.v2<a> workshop.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Mar 2024</b>
        I will give a talk at the <a href="https://cv4aec.github.io" target="_blank">CV4AEC Workshop</a> at <a href="https://cvpr.thecvf.com">CVPR'24</a> in Seattle.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Feb 2024</b>
        <a href="https://scenefun3d.github.io" target="_blank">SceneFun3D</a> is accepted at <a href="https://cvpr.thecvf.com">CVPR'24</a> as <b>üèÜ Oral</b> in Seattle, great work with <a href="https://alexdelitzas.github.io" target="_blank">Alex Delitzas</a> and <a href="https://aycatakmaz.github.io" target="_blank">Ayca Takmaz</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jan 2024</b>
        <a href="https://arxiv.org/abs/2401.09939" target="_blank">ICGNet</a> is accepted at <a href="https://2024.ieee-icra.org">ICRA'24</a> in Yokohama, great work with <a href="https://vas.mpi-inf.mpg.de/rene-zurbrugg/" target="_blank">Ren√© Zurbr√ºgg</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jan 2024</b>
        <a href="https://opennerf.github.io">OpenNeRF</a> and <a href="https://ywyue.github.io/AGILE3D/" target="_blank">AGILE3D</a> are accepted to <a href="https://iclr.cc/Conferences/2024">ICLR'24</a> in Vienna.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jan 2024</b>
       I gave a talk on <a href="https://www.youtube.com/watch?v=diMHj55fSSA">High-Fidelity Open-Vocabulary 3D Scene Understanding</a> at the <a href="https://www.youtube.com/@MontrealRobotics/videos?view=2&sort=dd&live_view=503&shelf_id=0" target="_blank">Mila Robot Learning Seminar</a>.
      </li>
    </ul>
    
    <a data-toggle="collapse" href="#more_news" role="button" aria-expanded="false" aria-controls="bibtex_mix3d">
    Previous news
    </a>

    <div class="collapse" id="more_news">
    <ul class="list-unstyled">
      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Dec 2023</b>
        The second iteration of our <a href="https://opensun3d.github.io">Open-Vocabulary 3D Scene Understanding Workshop</a> will be held in conjunction with <a href="https://cvpr.thecvf.com" target="_blank">CVPR'24</a> in Seattle.
      </li>
      
      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Dec 2023</b>
        Our <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reivewers" target="_blank">NeurIPS 2023</a> paper on open-vacbulary 3D instance segmentation method <a href="https://openmask3d.github.io">OpenMask3D</a> was featured in the <a href="https://www.rsipvision.com/ComputerVisionNews-2023December/2/">Computer Vision News</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Nov 2023</b>
        I was recognized as top reviewer for <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reivewers" target="_blank">NeurIPS 2023</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Oct 2023</b>
        Our work <a target="_blank"  href="http://labelmaker3d.github.io">LabelMaker</a> was accepted at <a href="https://3dvconf.github.io/2024/" target="_blank">3DV'24</a> in Davos, Switzerland.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Sep 2023</b>
        Our open-set 3D instance segmentation <a target="_blank"  href="https://openmask3d.github.io/">OpenMask3D</a> was accepted at <a href="https://nips.cc/Conferences/2023" target="_blank">NeuRIPS'23</a> in New Orleans.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Sep 2023</b>
        I will give a keynote talk at the ICCV'23 <a target="_blank"  href="https://cvaad-workshop.github.io/">CVAAD</a> workshop.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Aug 2023</b>
        I will serve as areas chair (AC) for <a target="_blank" href="https://wacv2024.thecvf.com/">WACV'24</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jul 2023</b>
        Our work on 3D human segmentation <a target="_blank"  href="https://human-3d.github.io/">Human3D</a> was accepted at  <a target="_blank" href="https://iccv2023.thecvf.com/">ICCV'23</a> in Paris.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jun 2023 </b>
        Check out our latest work on open-set 3D scene segmentation
        <a href="https://openmask3d.github.io" target="_blank">OpenMask3D</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jun 2023 </b>
        I will serve as senior program committee (SPC) for
        <a href="https://aaai.org/Conferences/AAAI-24/" target="_blank">AAAI 2024</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Mar 2023</b>
        Our workshop <a target="_blank"  href="https://opensun3d.github.io/">OpenSun3D</a> on Open-Vocabulary 3D Scene Understanding will be held in conjunction with  <a target="_blank" href="https://iccv2023.thecvf.com/">ICCV'23</a> in Paris.
      </li>
      
      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Feb 2023</b>
        Our paper <a target="_blank"  href="https://ywyue.github.io/RoomFormer/">RoomFormer</a> is accepted at <a target="_blank" href="https://cvpr2023.thecvf.com/">CVPR'23</a>.
        </li>

      <li style='margin-bottom: 5px'>
      <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jan 2023</b>
      Our paper <a target="_blank"  href="https://jonasschult.github.io/Mask3D/">Mask3D</a> was accepted at <a target="_blank" href="https://www.icra2023.org/">ICRA'23</a>.
      Check out the <a href="http://francisengelmann.github.io/mask3d" target="_blank">online demo</a>.
      </li>

      <li style='margin-bottom: 5px'>
      <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Dec 2022</b>
      I received the <a href="https://ethz.ch/en/research/research-promotion/seed-projects/supported-projects.html" target="_blank">ETH Zurich Career Seed Award</a>.
      </li>

      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Aug 2022 </b>
        Our <a href="https://jonasschult.github.io/Mask3D/">Mask3D</a> approach ranks 1<sup>st</sup> on
        <a href="https://kaldir.vc.in.tum.de/scannet_benchmark/semantic_instance_3d">ScanNet</a>,
        <a href="https://kaldir.vc.in.tum.de/scannet_benchmark/scannet200_semantic_instance_3d">ScanNet200</a> and 2<sup>nd</sup> on
        <a href="https://codalab.lisn.upsaclay.fr/competitions/4646#results">STPLS3D</a>.
        </li>
  
        <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Aug 2022 </b>
        One paper accepted at the ECCV 2022 <a href="https://avvision.xyz/eccv22/">AVVision Workshop</a>.
        </li>
  
      <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jul 2022 </b>
        I will serve as senior program committee (SPC) for
        <a href="https://aaai.org/Conferences/AAAI-23/" target="_blank">AAAI 2023</a>.
        </li>
  
        <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jul 2022 </b>
        Our paper <a href="https://virtualhumans.mpi-inf.mpg.de/box2mask/" target="_blank">Box2Mask</a>
        on weakly supervised 3D instance segmentation using bounding box annotations is accepted as oral (2.7%) to
        <a href="https://eccv2022.ecva.net/" target="_blank">ECCV 2022</a> in Tel Aviv.
        </li>
  
        <li style='margin-bottom: 5px'>
        <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jun 2022 </b>
        I gave an invited talk at the <a target="_blank" href="http://www.scan-net.org/cvpr2022workshop/#speakers">CVPR 2022 ScanNet workshop<a/> in New Orleans.
        </li>
  
        <li style='margin-bottom: 5px'>
          <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jun 2022 </b>
        Our winning entry on 2D floorplan reconstruction from large-scale point clouds was presented at <a href="https://cv4aec.github.io/">CV4AEC</a>
        with <a href="https://www.linkedin.com/in/ekincelikkan/" target="_blank">Ekin Celikkan</a>
        and <a href="https://theodorakontogianni.github.io/" target="_blank">Theodora Kontogianni</a>.
        </li>

        <li style='margin-bottom: 5px'>
          <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>Jun 2022 </b>
        Our model Mix3D won first place on the <a href="http://kaldir.vc.in.tum.de/scannet_benchmark/semantic_label_3d" target="_blank">ScanNet 3D Semantic Segmentaion challenge</a>  with
        <a href="https://nekrasov.dev/" target="_blank">Alexey Nekrasov</a> and
        <a href="https://jonasschult.github.io/" target="_blank">Jonas Schult</a>.
        </li>

        <li style='margin-bottom: 5px'>
          <b class="mr-4 p-teaser float-sm-left mb-sm-1" style='min-width: 80px'>May 2022 </b>
        I will co-organize the <a href="https://sites.google.com/view/egocentric-hand-body-activity" target="_blank">HBHA workshop</a> on
        human body, hands, and activities from egocentric and multi-view cameras at ECCV 2022.
      </li>

    </ul>
  </div>

  <br/>
  <br/>

      <h3 class="mb-3 text-center text-sm-left" id="publications">Publications</h3>

      <ul class="list-unstyled">

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_fungraph3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 55px;" />
            <p class="text-left">
              <span class="p-title">Open-Vocabulary Functional 3D Scene Graphs for Real-World Indoor Spaces</span></br>
              <span class="p-authors">
                Chenyangguang Zhang<sup>*</sup>, Alexandros Delitzas<sup>*</sup>, Fangjinhua Wang, Ruida Zhang, Xiangyang Ji, Marc Pollefeys, <u>Francis Engelmann</u>
              </span></br>
              <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2025.</span></br>

              <a class="mr-3" target="_blank" href="http://arxiv.org/abs/2503.19199"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_fungraph3d" role="button" aria-expanded="false" aria-controls="bibtex_fungraph3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://openfungraph.github.io/"><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_fungraph3d">
                <div class="card card-body">
<pre class="p-bibtex">@inproceedings{zhang2025fungraph3d, 
  title = {Open-Vocabulary Functional 3D Scene Graphs for Real-World Indoor Spaces}, 
  author = {Zhang, Chenyangguang and Delitzas, Alexandros and Wang, Fangjinhua and Zhang, Ruida and Ji, Xiangyang and Pollefeys, Marc and Engelmann, Francis}, 
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  year = {2025}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_arkitlabelmaker.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 55px;" />
            <p class="text-left">
              <span class="p-title">ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding</span></br>
              <span class="p-authors">
                Guangda Ji, Silvan Weder, <u>Francis Engelmann</u>, Marc Pollefeys, Hermann Blum
              </span></br>
              <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2025.</span></br>

              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2410.13924"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_arkitlabelmaker" role="button" aria-expanded="false" aria-controls="bibtex_arkitlabelmaker"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href=""><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_arkitlabelmaker">
                <div class="card card-body">
<pre class="p-bibtex">@inproceedings{zhang2025fungraph3d, 
  title = {ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding}, 
  author = {Ji, Guangda and Weder, Silvan and Engelmann, Francis and Pollefeys, Marc and Blum, Hermann}, 
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  year = {2025}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>



        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_search3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 55px;" />
            <p class="text-left">
              <span class="p-title">Search3D: Hierarchical Open-Vocabulary 3D Segmentation</span></br>
              <span class="p-authors">
                Ayca Takmaz, Alexandros Delitzas, Robert W. Sumner, <u>Francis Engelmann</u><sup>*</sup>, Johanna Wald<sup>*</sup>, Federico Tombari
              </span></br>
              <span class="p-conference">IEEE Robotics and Automation Letters (RA-L), 2025.</span></br>

              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2409.18431"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_search3d" role="button" aria-expanded="false" aria-controls="bibtex_search3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://search3d-segmentation.github.io/"><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_search3d">
                <div class="card card-body">
  <pre class="p-bibtex">@article{takmaz2025search3d,
  title={{Search3D: Hierarchical Open-Vocabulary 3D Segmentation}},
  author={Takmaz, Ayca and Delitzas, Alexandros and Sumner, Robert W. and Engelmann, Francis and Wald, Johanna and Tombari, Federico},
  journal={IEEE Robotics and Automation Letters (RA-L)},
  year={2025}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_opencity3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 55px;" />
            <p class="text-left">
              <span class="p-title">OpenCity3D: What do Vision-Language Models know about Urban Environments?</span></br>
              <span class="p-authors">
                Valentin Bieri, Marco Zamboni, Nicolas S. Blumer, Qingxuan Chen, <u>Francis Engelmann</u>
              </span></br>
              <span class="p-conference">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2025.</span></br>

              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_opencity3d" role="button" aria-expanded="false" aria-controls="bibtex_opencity3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://opencity3d.github.io/"><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_opencity3d">
                <div class="card card-body">
<pre class="p-bibtex">@inproceedings{zhang2025fungraph3d, 
  title = {{OpenCity3D: 3D Urban Scene Understanding with Vision-Language Models}}, 
  author = {Bieri, Valentin and Zamboni, Marco and Blumer, Nicolas S. and Chen, Qingxuan and Engelmann, Francis}, 
  booktitle = {IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  year = {2025}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_p2pbridge.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">P2P-Bridge: Diffusion Bridges for 3D Point Cloud Denoising</span></br>
              <span class="p-authors">
                Mathias Vogel, Keisuke Tateno, Marc Pollefeys, Federico Tombari, Marie-Julie Rakotosaona, <u>Francis Engelmann</u>
              </span></br>
              <span class="p-conference">European Conference on Computer Vision (ECCV), 2024.</span></br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2408.16325"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_p2pbrdige" role="button" aria-expanded="false" aria-controls="bibtex_p2pbrdige"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://p2p-bridge.github.io"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/matvogel/P2P-Bridge"><i class="fa fa-file-code-o"></i> Code</a>

              <div class="collapse" id="bibtex_p2pbrdige">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{delitzas2024scenefun3d, 
    author = {Vogel, Mathias and Tateno, Keisuke and Pollefeys, Marc and Tombari, Federico and Rakotosaona, Marie-Julie and Engelmann, Francis}, 
    title = {P2P-Bridge: Diffusion Bridges for 3D Point Cloud Denoising}, 
    booktitle = {{European Conference on Computer Vision (ECCV)}},
    year = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>


        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_segment3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 55px;" />
            <p class="text-left">
              <span class="p-title">Segment3D: Learning Fine-Grained Class-Agnostic 3D Segmentation without Manual Labels</span></br>
              <span class="p-authors">
                Rui Huang, Songyou Peng, Ay√ßa Takmaz,  Federico Tombari,
Marc Pollefeys,  Shiji Song,  Gao Huang,  <u>Francis Engelmann</u>
              </span></br>
              <span class="p-conference">European Conference on Computer Vision (ECCV), 2024.</span></br>

              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2312.17232"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_segment3d" role="button" aria-expanded="false" aria-controls="bibtex_segment3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://segment3d.github.io"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://mix3d-demo.nekrasov.dev/segment3d/"><i class="fa fa-file-pdf-o"></i> Demo</a>

              <div class="collapse" id="bibtex_segment3d">
                <div class="card card-body">
  <pre class="p-bibtex">  @inproceedings{Huang2023Segment3D,
  author    = {Huang, Rui and Peng, Songyou and Takmaz, Ayca and Tombari, Federico and Pollefeys, Marc and Song, Shiji and Huang, Gao and Engelmann, Francis},
  title     = {{Segment3D: Learning Fine-Grained Class-Agnostic 3D Segmentation without Manual Labels}},
  booktitle = {{European Conference on Computer Vision (ECCV)}},
  year      = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_scenegraphloc.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 5px;" />
            <p class="text-left">
              <span class="p-title">SceneGraphLoc: Cross-Modal Coarse Visual Localization on 3D Scene Graphs</span></br>
              <span class="p-authors">
                Yang Miao, <u>Francis Engelmann</u>, Olga Vysotska, Federico Tombari, Marc Pollefeys, D√°niel B√©la Bar√°th
              </span></br>
              <span class="p-conference">European Conference on Computer Vision (ECCV), 2024.</span></br>

              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2404.00469"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_scenegraphloc" role="button" aria-expanded="false" aria-controls="bibtex_scenegraphloc"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://scenegraphloc.github.io"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/y9miao/VLSG"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_scenegraphloc">
                <div class="card card-body">
 <pre class="p-bibtex">@inproceedings{miao2024scenegraphloc,
  author    = {Miao, Yang and Engelmann, Francis and Vysotska, Olga and Tombari, Federico and Pollefeys, Marc and Bar√°th, D√°niel B√©la},
  title     = {{SceneGraphLoc: Cross-Modal Coarse Visual Localization on 3D Scene Graphs}},
  booktitle = {{European Conference on Computer Vision (ECCV)}},
  year      = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_fit3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 5px;" />
            <p class="text-left">
              <span class="p-title">FiT3D: Improving 2D Feature Representations by 3D-Aware Fine-Tuning</span></br>
              <span class="p-authors">
                Yuanwen Yue, Anurag Das, <u>Francis Engelmann</u>, Siyu Tang, Jan Eric Lenssen
              </span></br>
              <span class="p-conference">European Conference on Computer Vision (ECCV), 2024.</span></br>

              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2407.20229"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_fit3d" role="button" aria-expanded="false" aria-controls="bibtex_fit3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://ywyue.github.io/FiT3D/"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/ywyue/FiT3D"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_fit3d">
                <div class="card card-body">
 <pre class="p-bibtex">@inproceedings{miao2024scenegraphloc,
  author    = {Yue, Yuanwen and Das, Anurag and Engelmann, Francis and Tang, Siyu and Lenssen, Jan Eric},
  title     = {{Improving 2D Feature Representations by 3D-Aware Fine-Tuning}},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_scenefun3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding: 10px 0 18px 0" />
            <p class="text-left">
              <span class="p-title">SceneFun3D: Fine-Grained Functionality and Affordance Understanding in 3D Scenes</span></br>
              <span class="p-authors">
                Alexandros Delitzas, Ayca Takmaz, Federico Tombari, Robert Sumner, Marc Pollefeys, <u>Francis Engelmann</u>
              </span></br>
              <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2024.</span></br>
              <b>üèÜ Oral Presentation</b></br>
              <a class="mr-3" target="_blank" href="https://alexdelitzas.github.io/assets/pdf/SceneFun3D.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_scenefun3d" role="button" aria-expanded="false" aria-controls="bibtex_scenefun3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://scenefun3d.github.io"><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_scenefun3d">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{delitzas2024scenefun3d, 
    author = {Alexandros Delitzas and Ayca Takmaz and Federico Tombari and Robert Sumner and Marc Pollefeys and Francis Engelmann}, 
    title = {SceneFun3D: Fine-Grained Functionality and Affordance Understanding in 3D Scenes}, 
    booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    year = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_spot-compose.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 30px" />
            <p class="text-left">
              <span class="p-title">Spot-Compose: A Framework for Open-Vocabulary Object Retrieval and
                Drawer Manipulation in Point Clouds</span></br>
              <span class="p-authors">
                Oliver Lemke, Zuria Bauer, Ren√© Zurbr√ºgg, Marc Pollefeys, <u>Francis Engelmann</u><sup>*</sup>, Hermann Blum<sup>*</sup></br>
                <b>üèÜ Best Paper Award</b> (ICRA <a href="https://mobile-manipulation.net/events/moma2024/" target="_blank">MOMA.v2</a> workshop)
              </span></br>
                <span class="p-conference">Proc. International Conference on Robotics and Automation Workshops (ICRAW), 2024.</span>
                </br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2404.12440"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_spotcompose" role="button" aria-expanded="false" aria-controls="bibtex_spotcompose"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://spot-compose.github.io"><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_spotcompose">
                <div class="card card-body">
  <pre class="p-bibtex">@article{zurbrugg2024icgnet,
  title     = {{Spot-Compose: A Framework for Open-Vocabulary Object Retrieval and Drawer Manipulation in Point Clouds}},
  author={Oliver Lemke and Zuria Bauer and Ren{\'e} Zurbr{\"u}gg and Marc Pollefeys and Francis Engelmann and Hermann Blum},
  journal   = {Internationl Conference on Robotics and Automation Workshops (ICRAW)},
  year      = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>


        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_icgnet.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 10px" />
            <p class="text-left">
              <span class="p-title">ICGNet: A Unified Approach for Instance-Centric Grasping</span></br>
              <span class="p-authors">
                Ren√© Zurbr√ºgg, Yifan Liu, <u>Francis Engelmann</u>, Suryansh Kumar, Marco Hutter, Vaishakh Patil, Fisher Yu
              </span></br>
                <span class="p-conference">Proc. International Conference on Robotics and Automation (ICRA), 2024.</span>
                </br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2401.09939"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_icgnet" role="button" aria-expanded="false" aria-controls="bibtex_icgnet"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://icgraspnet.github.io"><i class="fa fa-cube"></i> Project</a>

              <div class="collapse" id="bibtex_icgnet">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{zurbrugg2024icgnet,
  title = {{ICGNet: A Unified Approach for Instance-Centric Grasping}},
  author = {Zurbr{\"u}gg, Ren{\'e} and Liu, Yifan and Engelmann, Francis and Kumar, Suryansh and Hutter, Marco and Patil, Vaishakh and Yu, Fisher},
  booktitle = {Internationl Conference on Robotics and Automation (ICRA)},
  year = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_openmask3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">OpenMask3D: Open-Vocabulary 3D Instance Segmentation</span></br>
              <span class="p-authors">
                Ayca Takmaz, Elisabetta Fedele, Robert Sumner, Marc Pollefeys, Federico Tombari, <u>Francis Engelmann</u>
              </span></br>
                <span class="p-conference">Conference on Neural Information Processing Systems (NeurIPS), 2023.              </span></br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2306.13631"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_openmask3d" role="button" aria-expanded="false" aria-controls="bibtex_openmask3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://openmask3d.github.io"><i class="fa fa-cube"></i> Project</a>
              <!-- <a class="mr-3" target="_blank" href="https://neurips.cc/virtual/2023/poster/72623"><i class="fa fa-cube"></i> NeurIPS</a> -->
              <a class="mr-3" target="_blank" href="https://github.com/OpenMask3D/openmask3d"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_openmask3d">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{Takmaz2023openmask3d,
    title = {{OpenMask3D: Open-Vocabulary 3D Instance Segmentation}},
    author={Takmaz, Ay{\c{c}}a and Fedele, Elisabetta and Sumner, Robert W and Pollefeys, Marc and Tombari, Federico and Engelmann, Francis},
    booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
    year = {2023}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>
  
        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_labelmaker.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">LabelMaker: Automatic Semantic Label Generation from RGB-D Trajectories</span></br>
              <span class="p-authors">
                Silvan Weder, Hermann Blum, <u>Francis Engelmann</u> Marc Pollefeys
              </span></br>
                <span class="p-conference">International Conference on 3D Vision  (3DV), 2024.</span></br>
                <b>üèÜ Spotlight Presentation</b></br>
              <a class="mr-3" target="_blank" href="LabelMaker.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_labelmaker" role="button" aria-expanded="false" aria-controls="bibtex_labelmaker"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://labelmaker3d.github.io"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/cvg/LabelMaker/"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_labelmaker">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{Weder2024labelmaker3d,
    title = {{LabelMaker: Automatic Semantic Label Generation from RGB-D Trajectories}},
    author={Weder, Silvan and Blum, Hermann and Engelmann, Francis and Pollefeys, Marc},
    booktitle = {International Conference on 3D Vision (3DV)},
    year = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_openreno.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">OpenNeRF: Open-Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views</span></br>
              <span class="p-authors">
                <u>Francis Engelmann</u>, Fabian Manhardt, Michael Niemeyer, Keisuke Tateno, Marc Pollefeys, Federico Tombari 
              </span></br>
                <span class="p-conference">International Conference on Learning Representations (ICLR), 2024.</span></br>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/OpenSet3DSegmentation.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_opennerf" role="button" aria-expanded="false" aria-controls="bibtex_opennerf"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://opennerf.github.io"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/opennerf/opennerf"><i class="fa fa-file-code-o"></i> Code</a>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/opennerf/"><i class="fa fa-file-pdf-o"></i> Demo</a>
              <div class="collapse" id="bibtex_opennerf">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{engelmann2023opennerf,
    title = {{OpenNerf: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views}},
    author={Francis Engelmann, Fabian Manhardt, Michael Niemeyer, Keisuke Tateno, Marc Pollefeys, Federico Tombari},
    booktitle = {{International Conference on Learning Representations (ICLR)}},
    year = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_agile3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 15px" />
            <p class="text-left">
              <span class="p-title">AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation</span></br>
              <span class="p-authors">
                Yuanwen Yue, Sabarinath Mahadevan, Jonas Schult, <u>Francis Engelmann</u>, Bastian Leibe, Konrad Schindler, Theodora Kontogianni
              </span></br>
              <span class="p-conference">International Conference on Learning Representations (ICLR), 2024.              </span></br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2306.00977"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_agile3d" role="button" aria-expanded="false" aria-controls="bibtex_agile3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://ywyue.github.io/AGILE3D/"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/ywyue/AGILE3D"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_agile3d">
                <div class="card card-body">
  <pre class="p-bibtex">@inproceedings{yue2023agile3d,
    title     = {{AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation}},
    author    = {Yue, Yuanwen and Mahadevan, Sabarinath and Schult, Jonas and Engelmann, Francis and Leibe, Bastian and Schindler, Konrad and Kontogianni, Theodora},
    booktitle = {{International Conference on Learning Representations (ICLR)}},
    year      = {2024}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
        <div class="media-body text-center">
          <img src="teasers/teaser_human3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" />
          <p class="text-left">
            <span class="p-title">3D Segmentation of Humans in Point Clouds with Synthetic Data</span></br>
            <span class="p-authors">
              Ayca Takmaz, Jonas Schult, Irem Kaftan, Cafer Mertcan Akcay, Bastian Leibe, Robert Sumner, <u>Francis Engelmann</u>, Siyu Tang
            </span></br>
              <span class="p-conference">Proc. International Conference on Computer Vision (ICCV), 2023.              </span></br>
            <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2212.00786"><i class="fa fa-file-pdf-o"></i> Paper</a>
            <a class="mr-3" data-toggle="collapse" href="#bibtex_human3d" role="button" aria-expanded="false" aria-controls="bibtex_human3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
            <a class="mr-3" target="_blank" href="https://human-3d.github.io/"><i class="fa fa-cube"></i> Project</a>
            <a class="mr-3" target="_blank" href="https://github.com/jonasschult/Human3D"><i class="fa fa-file-code-o"></i> Code</a>
            <div class="collapse" id="bibtex_human3d">
              <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Takmaz2022human3d,
    title = {{3D Segmentation of Humans in Point Clouds with Synthetic Data}},
    author = {Ayca Takmaz, Jonas Schult, Irem Kaftan, Cafer Mertcan Akcay, Bastian Leibe, Robert Sumner, Francis Engelmann and Siyu Tang},
    booktitle = {{arXiv}},
    year = {2022}
}</pre>
                </div>
            </div>
          </p>
        </div>
      </li>

</br>

        <li class="media">
        <div class="media-body text-center">
          <img src="teasers/teaser_floorformer.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" />
          <p class="text-left">
            <span class="p-title">Connecting the Dots: Floorplan Reconstruction Using Two-Level Queries</span></br>
            <span class="p-authors">
              Yuanwen Yue, Theodora Kontogianni, Konrad Schindler, <u>Francis Engelmann</u>
            </span></br>
  <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2023.</span></br>
            <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2211.15658"><i class="fa fa-file-pdf-o"></i> Paper</a>
            <a class="mr-3" data-toggle="collapse" href="#bibtex_floorformer" role="button" aria-expanded="false" aria-controls="bibtex_floorformer"><i class="fa fa-file-text-o"></i> BibTeX</a>
            <a class="mr-3" target="_blank" href="https://ywyue.github.io/RoomFormer/"><i class="fa fa-cube"></i> Project</a>
            <a class="mr-3" target="_blank" href="https://github.com/ywyue/RoomFormer"><i class="fa fa-file-code-o"></i> Code</a>
            <div class="collapse" id="bibtex_floorformer">
              <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Yue2022floorformer,
    title = {{Connecting the Dots: Floorplan Reconstruction Using Two-Level Queries}},
    author = {Yuanwen Yue, Theodora Kontogianni, Konrad Schindler, Francis Engelmann},
    booktitle = {IEEE Computer Vision and Pattern Recognition Conference (CVPR)},
    year = {2023}
}</pre>
                </div>
            </div>
          </p>
        </div>
      </li>




        <li class="media">
        <div class="media-body text-center">
          <img src="teasers/teaser_mask3d.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" />
          <p class="text-left">
            <span class="p-title">Mask3D: Mask Transformer for 3D Semantic Instance Segmentation</span></br>
            <span class="p-authors">
              Jonas Schult, <u>Francis Engelmann</u>, Alexander Hermans, Or Litany, Siyu Tang, Bastian Leibe
            </span></br>
            <span class="p-conference">Proc. International Conference on Robotics and Automation (ICRA), 2023.</span></br>
            1st Place <a href="https://kaldir.vc.in.tum.de/scannet_benchmark/semantic_instance_3d">ScanNet Challenge</a></br>
            <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2210.03105"><i class="fa fa-file-pdf-o"></i> Paper</a>
            <a class="mr-3" data-toggle="collapse" href="#bibtex_mask3d" role="button" aria-expanded="false" aria-controls="bibtex_mix3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
            <a class="mr-3" target="_blank" href="https://jonasschult.github.io/Mask3D/"><i class="fa fa-cube"></i> Project</a>
            <a class="mr-3" target="_blank" href="https://github.com/JonasSchult/Mask3D"><i class="fa fa-file-code-o"></i> Code</a>
            <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/mask3d/index.html"><i class="fa fa-file-pdf-o"></i> Demo</a>
            <div class="collapse" id="bibtex_mask3d">
              <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Schult2022mask3d,
    title = {{Mask3D: Mask Transformer for 3D Semantic Instance Segmentation}},
    author = {Schult, Jonas and Engelmann, Francis and Hermans, Alexander and Litany, Or and Tang, Siyu and Leibe, Bastian},
    booktitle = {Internationl Conference on Robotics and Automation (ICRA)},
    year = {2022}
}</pre>
                </div>
            </div>
          </p>
        </div>
      </li>


      <li class="media">
      <div class="media-body text-center" style="margin-top: 25px">
        <img src="teasers/teaser_box2mask.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="margin: 20px 0px 0px 0px" />
        <p class="text-left">
          <span class="p-title">Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes</span></br>
          <span class="p-authors">
            Julian Chibane, <u>Francis Engelmann</u>, Tuan Anh Tran, Gerard Pons-Moll
          </span></br>
          <span class="p-conference">European Conference on Computer Vision (ECCV), 2022.</span></br>
<b>üèÜ Oral Presentation</b></br>
          <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2206.01203"><i class="fa fa-file-pdf-o"></i> Paper</a>
          <a class="mr-3" data-toggle="collapse" href="#bibtex_box2mask" role="button" aria-expanded="false" aria-controls="bibtex_mix3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
          <a class="mr-3" target="_blank" href="https://virtualhumans.mpi-inf.mpg.de/box2mask/"><i class="fa fa-cube"></i> Project</a>
          <a class="mr-3" target="_blank" href="https://virtualhumans.mpi-inf.mpg.de/box2mask/Box2Mask_Video.mp4"><i class="fa fa-youtube"></i> Video</a>
          <a class="mr-3" target="_blank" href="https://github.com/jchibane/Box2Mask"><i class="fa fa-file-code-o"></i> Code</a>
          <div class="collapse" id="bibtex_box2mask">
            <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Chibane2022box2mask,
  title = {Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes},
  author = {Chibane, Julian and Engelmann, Francis and Tran, Tuan Anh and Pons-Moll, Gerard},
  booktitle = {{European Conference on Computer Vision (ECCV)}},
  year = {2022}
}</pre>
              </div>
          </div>
        </p>
      </div>
    </li>

    <li class="media">
      <div class="media-body text-center" style="margin-top: 25px">
        <img src="teasers/teaser_4dStOP.jpg" class="mr-4 p-teaser float-sm-left mb-sm-1" style="padding-bottom: 30px" />
        <p class="text-left">
          <span class="p-title">4D-StOP: Panoptic Segmentation of 4D LiDAR using Spatio-temporal Object Proposal Generation and Aggregation</span></br>
          <span class="p-authors">
            Lars Kreuzberg, Idil Esen Zulfikar, Sabarinath Mahadevan, <u>Francis Engelmann</u>, Bastian Leibe
          </span></br>
          <span class="p-conference">European Conference on Computer Vision Workshops (ECCVW), 2022.</span></br>
          <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2209.14858v1"><i class="fa fa-file-pdf-o"></i> Paper</a>
          <a class="mr-3" data-toggle="collapse" href="#bibtex_4dstop" role="button" aria-expanded="false" aria-controls="bibtex_4dstop"><i class="fa fa-file-text-o"></i> BibTeX</a>
          <a class="mr-3" target="_blank" href="https://github.com/larskreuzberg/4d-stop"><i class="fa fa-file-code-o"></i> Code</a>
          <div class="collapse" id="bibtex_4dstop">
            <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Kreuzberg22ECCVW,
  title = {4D-StOP: Panoptic Segmentation of 4D LiDAR using Spatio-temporal Object Proposal Generation and Aggregation},
  author = {Lars Kreuzberg, Idil Esen Zulfikar, Sabarinath Mahadevan, Francis Engelmann, Bastian Leibe},
  booktitle = {{European Conference on Computer Vision Workshops (ECCVW)}},
  year = {2022}
}</pre>
              </div>
          </div>
        </p>
      </div>
    </li>


        <li class="media">
        <div class="media-body text-center">
          <img src="teasers/teaser_mix3d.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
          <p class="text-left">
            <span class="p-title">Mix3D: Out-of-Context Data Augmentation for 3D Scenes</span></br>
            <span class="p-authors">
              Alexey Nekrasov, Jonas Schult, Or Litany, Bastian Leibe, <u>Francis Engelmann</u>
            </span></br>
            <span class="p-conference">International Conference on 3D Vision (3DV), 2021.</span></br>
            <b>üèÜ Oral Presentation</b>, 1st Place <a href="http://kaldir.vc.in.tum.de/scannet_benchmark/semantic_label_3d">ScanNet Challenge</a></br>
            <a class="mr-3" target="_blank" href="https://arxiv.org/abs/2110.02210"><i class="fa fa-file-pdf-o"></i> Paper</a>
            <a class="mr-3" data-toggle="collapse" href="#bibtex_mix3d" role="button" aria-expanded="false" aria-controls="bibtex_mix3d"><i class="fa fa-file-text-o"></i> BibTeX</a>
            <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/mask3d/"><i class="fa fa-file-pdf-o"></i> Demo</a>
            <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/mask3d/index.html"><i class="fa fa-cube"></i> Project</a>
            <a class="mr-3" target="_blank" href="https://github.com/kumuji/mix3d"><i class="fa fa-file-code-o"></i> Code</a>

            <div class="collapse" id="bibtex_mix3d">
              <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Nekrasov213DV,
  title     = {{Mix3D: Out-of-Context Data Augmentation for 3D Scenes}},
  author    = {Nekrasov, Alexey and Schult, Jonas and Litany, Or and Leibe, Bastian and Engelmann, Francis},
  booktitle = {{International Conference on 3D Vision (3DV)}},
  year      = {2021}
}</pre>
                </div>
            </div>
          </p>
        </div>
      </li>


          <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_points2objects.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">From Points to Multi-Object 3D Reconstruction</span></br>
              <span class="p-authors"><u>Francis Engelmann</u>, Konstantinos Rematas, Bastian Leibe, Vittorio Ferrari</span></br>
              <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2021.</span></br>
              <a class="mr-3" target="_blank" href="https://openaccess.thecvf.com/content/CVPR2021/html/Engelmann_From_Points_to_Multi-Object_3D_Reconstruction_CVPR_2021_paper.html"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/points2objects/cvpr21_points2objects_poster.pdf"><i class="fa fa-file-pdf-o"></i> Poster</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_p2o" role="button" aria-expanded="false" aria-controls="bibtex_3dmpa"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/points2objects/"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/tensorflow/graphics/tree/master/tensorflow_graphics/projects/points_to_3Dobjects"><i class="fa fa-file-code-o"></i> Code</a>

              <div class="collapse" id="bibtex_p2o">
                <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Engelmann21CVPR,
  title     = {{From Points to Multi-Object 3D Reconstruction}},
  author    = {Engelmann, Francis and Rematas, Konstantinos and Leibe, Bastian and Ferrari, Vittorio},
  booktitle = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
  year      = {2021}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media">
          <div class="media-body text-center">
            <img src="teasers/teaser_3D-MPA.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation</span></br>
              <span class="p-authors"><u>Francis Engelmann</u>, Martin Bokeloh, Alireza Fathi, Bastian Leibe, Matthias Nie√üner</span></br>
              <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2020.</span></br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/pdf/2003.13867.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>
              <a class="mr-3" data-toggle="collapse" href="#bibtex_3dmpa" role="button" aria-expanded="false" aria-controls="bibtex_3dmpa"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/3D-MPA/"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://www.youtube.com/watch?v=ifL8yTbRFDk&feature=youtu.be"><i class="fa fa-youtube"></i> Video</a>
              <div class="collapse" id="bibtex_3dmpa">
                <div class="card card-body">
<pre class="p-bibtex">@inproceedings{Engelmann20CVPR,
  title     = {{3D-MPA: Multi Proposal Aggregation for 3D Semantic Instance Segmentation}},
  author    = {Engelmann, Francis and Bokeloh, Martin and Fathi, Alireza and Leibe, Bastian and Nie{\ss}ner, Matthias},
  booktitle = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
  year      = {2020}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_DCM-Net.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">DualConvMesh-Net: Joint Geodesic and Euclidean Convolutions on 3D Meshes</span></br>
              <span class="p-authors">Jonas Schult<top>*</top>, <u>Francis Engelmann</u><top>*</top>, Theodora Kontogianni, Bastian Leibe</span></br>
              <span class="p-conference">Proc. Computer Vision and Pattern Recognition (CVPR), 2020.</span><br />
              <b>üèÜ Oral Presentation</b></br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/pdf/2004.01002.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_dmcnet" role="button" aria-expanded="false" aria-controls="bibtex_dmcnet"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://visualcomputinginstitute.github.io/dcm-net/"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://github.com/VisualComputingInstitute/dcm-net"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_dmcnet">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{Schult20CVPR,
  title     = {{DualConvMesh-Net: Joint Geodesic and Euclidean Convolutions on 3D Meshes}},
  author    = {Jonas Schult and Francis Engelmann and Theodora Kontogianni and Bastian Leibe},
  booktitle = {{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}},
  year      = {2020}
}
</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_DPC.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds</span></br>
              <span class="p-authors"><u>Francis Engelmann</u>, Theodora Kontogianni, Bastian Leibe</span></br>
              <span class="p-conference">Proc. International Conference on Robotics and Automation (ICRA), 2020.</span></br>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/DPC/engelmann_icra2020_dpc.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_dpc" role="button" aria-expanded="false" aria-controls="bibtex_dpc"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/DPC/engelmann_cvpr2019_workshop_dpc.pdf"><i class="fa fa-file-pdf-o"></i> Poster</a>&nbsp;
              <a class="mr-3" target="_blank" href="https://francisengelmann.github.io/DPC/"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://www.youtube.com/watch?v=JDfFmuOvMkM&feature=youtu.be"><i class="fa fa-youtube"></i> Video</a>
              <div class="collapse" id="bibtex_dpc">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{Engelmann20ICRA,
  author    = {Engelmann, Francis and  Kontogianni, Theodora and Leibe, Bastian},
  title     = {{Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds}},
  booktitle = {{International Conference on Robotics and Automation (ICRA)}},
  year      = {2020}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_3D-BEVIS.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">3D-BEVIS: Bird‚Äôs-Eye-View Instance Segmentation</span></br>
              <span class="p-authors">Cathrin Elich, <u>Francis Engelmann</u>, Jonas Schult, Theodora Kontogianni, Bastian Leibe</span></br>
              <span class="p-conference">Proc. German Conference on Pattern and Recognition (GCPR), 2019.</span></br>
              <b>üèÜ YRF DAGM Best Master's Thesis Award 2019</b> <a target="_blank" href="https://www.dagm.de/preistraeger/dagm-yrf-best-masters-thesis-awards/"><i class="fa fa-external-link"></i><a><br />
              <a class="mr-3" target="_blank" href="https://arxiv.org/pdf/1904.02199.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_3dbevis" role="button" aria-expanded="false" aria-controls="bibtex_3dbevis"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <div class="collapse" id="bibtex_3dbevis">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{ElichGCPR19,
  title     = {{3D-BEVIS: Birds-Eye-View Instance Segmentation}},
  author    = {Elich, Cathrin and Engelmann, Francis and Schult, Jonas and Kontogianni, Theodora and Leibe, Bastian},
  booktitle = {{German Conference on Pattern Recognition (GCPR)}},
  year      = {2019}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_KWYND.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">Know What Your Neighbors Do: 3D Semantic Segmentation of Point Clouds</span></br>
              <span class="p-authors"><u>Francis Engelmann</u>, Theodora Kontogianni, Jonas Schult, Bastian Leibe</span></br>
              <span class="p-conference">Proc. European Conference on Computer Vision Workshops (ECCVW), 2018.</span></br>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/know-what-your-neighbors-do-3d-semantic-segmentation-of-point-clouds/W63P26.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_kwynd" role="button" aria-expanded="false" aria-controls="bibtex_kwynd"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <div class="collapse" id="bibtex_kwynd">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{Engelmann18ECCVW,
  author    = {Francis Engelmann and Theodora Kontogianni and Jonas Schult and Bastian Leibe},
  title     = {Know What Your Neighbors Do: 3D Semantic Segmentation of Point Clouds},
  booktitle = {{European Conference on Computer Vision Workshops (ECCVW)}},
  year      = {2018}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_Exploring.png" class="mr-4 p-teaser float-sm-left mb-sm-5" />
            <p class="text-left">
              <span class="p-title">Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds</span></br>
              <span class="p-authors"><u>Francis Engelmann</u><top>*</top>, Theodora Kontogianni<top>*</top>, Alexander Hermans, Bastian Leibe</span></br>
              <span class="p-conference">Proc. Internationcal Conference on Computer Vision Workshops (ICCVW), 2017.</span><br />
              <b>üèÜ Oral Presentation</b></br>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/PID4967025.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_exploring" role="button" aria-expanded="false" aria-controls="bibtex_exploring"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/iccvw17_3dsemseg_poster.pdf"><i class="fa fa-file-pdf-o"></i> Poster</a>&nbsp;
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/page/3dsemseg"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://www.youtube.com/watch?v=w--rpu2-HFs&feature=emb_logo"><i class="fa fa-youtube"></i> Video</a>
              <a class="mr-3" target="_blank" href="https://github.com/VisualComputingInstitute/3d-semantic-segmentation"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_exploring">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{3dsemseg_ICCVW17,
  author    = {Francis Engelmann and Theodora Kontogianni and Alexander Hermans and Bastian Leibe},
  title     = {Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds},
  booktitle = {{International Conference on Computer Vision Workshops (ICCVW)},
  year      = {2017}
}
</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_vislam.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">Keyframe-Based Visual-Inertial Online SLAM with Relocalization</span></br>
              <span class="p-authors">Anton Kasyanov, <u>Francis Engelmann</u>, J√∂rg St√ºckler, Bastian Leibe</span></br>
              <span class="p-conference">Proc. International Conference on Intelligent Robots and Systems (IROS), 2017.</span></br>
              <a class="mr-3" target="_blank" href="https://arxiv.org/pdf/1702.02175.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_vislam" role="button" aria-expanded="false" aria-controls="bibtex_vislam"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <div class="collapse" id="bibtex_vislam">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{Kasyanov17IROS,
  title     = {{Keyframe-Based Visual-Inertial Online SLAM with Relocalization}},
  author    = {Anton Kasyanov and Francis Engelmann and J\"org St\"uckler and Bastian Leibe},
  booktitle = {{International Conference on Intelligent Robots and Systems (IROS)}},
  year      = {2017}
}</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_SAMP.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">SAMP: Shape and Motion Priors for 4D Vehicle Reconstruction</span></br>
              <span class="p-authors"><u>Francis Engelmann</u>, J√∂rg St√ºckler, Bastian Leibe</span></br>
              <span class="p-conference">Proc. Winter Conference on Applications of Computer Vision (WACV), 2017.</span></br>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/EngelmannWACV17_x8euNDK.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_samp" role="button" aria-expanded="false" aria-controls="bibtex_samp"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/Engelmann2017WACV_poster.pdf"><i class="fa fa-file-pdf-o"></i> Poster</a>&nbsp;
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/Engelmann2017WACV_supp.pdf"><i class="fa fa-file-pdf-o"></i> Supplementary Material</a>&nbsp;
              <a class="mr-3" target="_blank" href="https://www.vci.rwth-aachen.de/publication/00146/"><i class="fa fa-cube"></i> Project</a>
              <div class="collapse" id="bibtex_samp">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{Engelmann17WACV,
  author    = {Francis Engelmann and J{\"{o}}rg St{\"{u}}ckler and Bastian Leibe},
  title     = {{SAMP: Shape and Motion Priors for 4D Vehicle Reconstruction}},
  booktitle = {{Winter Conference on Applications of Computer Vision (WACV)}},
  year      = {2017}
}
</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>

        <li class="media my-4">
          <div class="media-body text-center">
            <img src="teasers/teaser_GCPR.png" class="mr-4 p-teaser float-sm-left mb-sm-1" />
            <p class="text-left">
              <span class="p-title">Joint Object Pose Estimation and Shape Reconstruction in Urban Street Scenes Using 3D Shape Priors</span></br>
              <span class="p-authors"><u>Francis Engelmann</u>, J√∂rg St√ºckler, Bastian Leibe</span></br>
              <span class="p-conference">Proc. German Conference on Pattern Recognition (GCPR), 2016.</span><br />
              <b>üèÜ Oral Presentation</b></br>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/EngelmannGCPR16_SZa4QgP.pdf"><i class="fa fa-file-pdf-o"></i> Paper</a>&nbsp;
              <a class="mr-3" data-toggle="collapse" href="#bibtex_gcpr" role="button" aria-expanded="false" aria-controls="bibtex_gcpr"><i class="fa fa-file-text-o"></i> BibTeX</a>
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/media/papers/EngelmannGCPR16_supplementary.pdf"><i class="fa fa-file-pdf-o"></i> Supplementary Material</a>&nbsp;
              <a class="mr-3" target="_blank" href="https://www.vision.rwth-aachen.de/page/shape_priors"><i class="fa fa-cube"></i> Project</a>
              <a class="mr-3" target="_blank" href="https://www.youtube.com/watch?v=vA0Q5M3eScM&feature=youtu.be"><i class="fa fa-youtube"></i> Video</a>
              <a class="mr-3" target="_blank" href="https://github.com/VisualComputingInstitute/ShapePriors_GCPR16"><i class="fa fa-file-code-o"></i> Code</a>
              <div class="collapse" id="bibtex_gcpr">
                <div class="card card-body">
<pre class="p-bibtex">
@inproceedings{Engelmann16GCPR,
  title     = {{Joint Object Pose Estimation and Shape Reconstruction in Urban Street Scenes Using 3D Shape Priors}},
  author    = {Francis Engelmann and J\"org St\"uckler and Bastian Leibe},
  booktitle = {{German Conference on Pattern Recognition (GCPR)}},
  year      = {2016}
}
</pre>
                  </div>
              </div>
            </p>
          </div>
        </li>
      </ul>

      <h2 class="mb-3 text-center text-sm-left">Projects</h2>

      <ul class="list-unstyled">

        <li class="media"><div class="media-body"><p>
          <a href="mask3d/index.html"><img src="project_mask3d.jpg" class="mr-4 p-project float-sm-left mb-sm-1" /></a>
          <span class="project" style="text-align: justify;">This is the online demo of <a href="https://jonasschult.github.io/Mask3D/">Mask3D<a/> our state-of-the-art 3D semantic instance segmentation method.
          You can upload your own 3D scan or reconstruction (.ply) and segment the scene into the semantic classes of ScanNet, including ScanNet 200. </span><br />
          <a class="mr-3" target="_blank" href="mask3d/index.html"><i class="fa fa-file-code-o"></i> Link</a>
        </p></li>

        <li class="media"><div class="media-body">
          <p>
          <a href="https://github.com/francisengelmann/PyViz3D"><img src="project_pyviz3d.png" class="mr-4 p-project float-sm-left mb-sm-1" /></a>
          <span>PyViz3D is a simple web-based visualizer for 3D point clouds and other primitives such as meshes, polylines, bounding boxes and labels. It is useful for quick protyping and remote development.</span>
          <br />
          <a class="mr-3" target="_blank" href="https://github.com/francisengelmann/PyViz3D"><i class="fa fa-file-code-o"></i> GitHub</a>
        </p></li>

        <li class="media"><div class="media-body"><p>
          <a href="https://www.thingiverse.com/thing:14198"><img src="project_fabscan.jpg" class="mr-4 p-project float-sm-left mb-sm-1" /></a>
          <span>FabScan is a do-it-yourself, open-source 3D laser scanner that I developed a long time ago as my Bachelor thesis at the RWTH Aachen <a href="https://hci.rwth-aachen.de/fabscan">FabLab</a>.</span>
          It consists of a webcam, line-laser, microcontroller, stepper-engines, and a turn-table. The project was featured on <a href="https://www.thingiverse.com/search?q=fabscan&page=1">Thingiverse</a> and is still maintained by Mario Lukas at <a href="https://fabscan.org">fabscan.org</a>.
          <!-- <a class="mr-3" target="_blank" href="https://github.com/francisengelmann/FabScan100"><i class="fa fa-file-code-o"></i> GitHub</a> -->
        </p></li>
        
        <br />
        <li class="media"><div class="media-body"><p>
          <span>Virtual KITTI 3D: Extension of the Virtual Kitti dataset including 3D cloud representations and refined semantic labels.</span><br />
          <a class="mr-3" target="_blank" href="https://github.com/VisualComputingInstitute/vkitti3D-dataset"><i class="fa fa-file-code-o"></i> Code</a>
        </p></div></li>

        <li class="media"><div class="media-body"><p>
          <span>Graph Convolutional Nets: Implementation of Kipf et al. graph convolutional networks.</span><br />
          <a class="mr-3" target="_blank" href="https://github.com/francisengelmann/GraphConvNets"><i class="fa fa-file-code-o"></i> Code</a>
        </p></div></li>

        <li class="media"><div class="media-body"><p>
          <span>Fast Voxel Traversal: Implementation of the Fast Voxel Traversal algorithm.</span><br />
          <a class="mr-3" target="_blank" href="https://github.com/francisengelmann/fast_voxel_traversal"><i class="fa fa-file-code-o"></i> Code</a>
        </p></div></li>

        <li class="media"><div class="media-body"><p>
          <span>Spectrum Analyzer: Some tools to visualize audio input using OpenAL and FFTW.</span><br />
          <a class="mr-3" target="_blank" href="https://github.com/francisengelmann/sound"><i class="fa fa-file-code-o"></i> Code</a>
        </p></div></li>

        <li class="media"><div class="media-body"><p>
          <span>MCMC-MH: Implementation of MCMC-MH and sudoku solver using MCMC.</span><br />
          <a class="mr-3" target="_blank" href="https://github.com/francisengelmann/mcmc"><i class="fa fa-file-code-o"></i> Code</a>
        </p></div></li>

      </ul>

    </main>

    <footer class="text-muted">
      <div class="container">
        <hr />
        <p align="center"><a href="#">Back to top <i class="fa fa-chevron-up"></i></a></p>
      </div>
    </footer>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  </body>
</html>
